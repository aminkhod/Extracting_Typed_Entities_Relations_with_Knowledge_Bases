{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import hazm\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import csv, re, pickle\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense, Flatten\n",
    "# import numpy as np\n",
    "# from keras.utils import to_categorical\n",
    "# import re\n",
    "# from utils import words_list, stopwords_list\n",
    "# from stopping_utility import *\n",
    "# import nltk\n",
    "# import wapiti\n",
    "\n",
    "from colorama import Back, Fore, Style\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from os import path\n",
    "from persian_wordcloud.wordcloud import PersianWordCloud, add_stop_words\n",
    "from wordcloud import STOPWORDS as EN_STOPWORDS\n",
    "from wordcloud_fa import WordCloudFa\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from matplotlib import font_manager as fm, rcParams\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# from sklearn import metrics\n",
    "# import sklearn.metrics as sm\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# from sklearn.cluster import Birch\n",
    "# from sklearn import manifold\n",
    "# import pyclustering as pyclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>body</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168298</td>\n",
       "      <td>2020-10-24 13:09:52</td>\n",
       "      <td>2020-10-24 13:09:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13980429001132</td>\n",
       "      <td>فیلم| عملیات توقیف نفتکش انگلیسی توسط تکاوران ...</td>\n",
       "      <td>فیلم عملیات توقیف نفتکش انگلیسی «Stena Impero»...</td>\n",
       "      <td>به گزارش خبرنگار دفاعی خبرگزاری فارس، فیلم عمل...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168314</td>\n",
       "      <td>2020-10-24 13:10:01</td>\n",
       "      <td>2020-10-24 13:10:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13980429001116</td>\n",
       "      <td>جزئیات جدیدی از توقیف نفتکش انگلیسی/ در اعمال ...</td>\n",
       "      <td>سخنگوی سپاه با اشاره به نقض قانون توسط نفتکش ا...</td>\n",
       "      <td>به گزارش گروه دفاعی خبرگزاری فارس، سردار رمضان...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>168316</td>\n",
       "      <td>2020-10-24 13:10:01</td>\n",
       "      <td>2020-10-24 13:10:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13980429000996</td>\n",
       "      <td>چهار کشتی ایرانی در انتظار سوخت در بنادر برزیل...</td>\n",
       "      <td>رویترز طی گزارشی نوشت دو کشتی دیگر ایران نیز د...</td>\n",
       "      <td>به گزارش گروه اقتصاد بین‌الملل فارس به نقل از ...</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168318</td>\n",
       "      <td>2020-10-24 13:10:03</td>\n",
       "      <td>2020-10-24 13:10:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13980429001007</td>\n",
       "      <td>نگرانی تجار برزیلی از خراب شدن تجارت با ایران/...</td>\n",
       "      <td>درحالی‌که رئیس‌جمهور برزیل تلاش می‌کند با جلب ...</td>\n",
       "      <td>به گزارش گروه اقتصاد بین‌الملل فارس به نقل از ...</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168320</td>\n",
       "      <td>2020-10-24 13:10:04</td>\n",
       "      <td>2020-10-24 13:10:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13980429001096</td>\n",
       "      <td>جدال با هویت دینی جامعه ایرانی؛ توصیه استعمارک...</td>\n",
       "      <td>شاخص‌ترین هویت زن ایرانی حتی از قرن‌های پیش از...</td>\n",
       "      <td>به گزارش گروه سیاسی خبرگزاری فارس، علی قربان‌ن...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id           created_at           updated_at  deleted_at  \\\n",
       "0  168298  2020-10-24 13:09:52  2020-10-24 13:09:52         NaN   \n",
       "1  168314  2020-10-24 13:10:01  2020-10-24 13:10:01         NaN   \n",
       "2  168316  2020-10-24 13:10:01  2020-10-24 13:10:01         NaN   \n",
       "3  168318  2020-10-24 13:10:03  2020-10-24 13:10:03         NaN   \n",
       "4  168320  2020-10-24 13:10:04  2020-10-24 13:10:04         NaN   \n",
       "\n",
       "             code                                              title  \\\n",
       "0  13980429001132  فیلم| عملیات توقیف نفتکش انگلیسی توسط تکاوران ...   \n",
       "1  13980429001116  جزئیات جدیدی از توقیف نفتکش انگلیسی/ در اعمال ...   \n",
       "2  13980429000996  چهار کشتی ایرانی در انتظار سوخت در بنادر برزیل...   \n",
       "3  13980429001007  نگرانی تجار برزیلی از خراب شدن تجارت با ایران/...   \n",
       "4  13980429001096  جدال با هویت دینی جامعه ایرانی؛ توصیه استعمارک...   \n",
       "\n",
       "                                                lead  \\\n",
       "0  فیلم عملیات توقیف نفتکش انگلیسی «Stena Impero»...   \n",
       "1  سخنگوی سپاه با اشاره به نقض قانون توسط نفتکش ا...   \n",
       "2  رویترز طی گزارشی نوشت دو کشتی دیگر ایران نیز د...   \n",
       "3  درحالی‌که رئیس‌جمهور برزیل تلاش می‌کند با جلب ...   \n",
       "4  شاخص‌ترین هویت زن ایرانی حتی از قرن‌های پیش از...   \n",
       "\n",
       "                                                body     genre  \n",
       "0  به گزارش خبرنگار دفاعی خبرگزاری فارس، فیلم عمل...  politics  \n",
       "1  به گزارش گروه دفاعی خبرگزاری فارس، سردار رمضان...  politics  \n",
       "2  به گزارش گروه اقتصاد بین‌الملل فارس به نقل از ...   economy  \n",
       "3  به گزارش گروه اقتصاد بین‌الملل فارس به نقل از ...   economy  \n",
       "4  به گزارش گروه سیاسی خبرگزاری فارس، علی قربان‌ن...  politics  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('news_202010261937.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'politics': 23491,\n",
       "         'economy': 15694,\n",
       "         'Undefined': 1957,\n",
       "         'recreation': 198,\n",
       "         'good': 342})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(data['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'استارت\\u200cآپ مشهدی\\u200cها برای عدالت\\u200cخواهی!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data[data['genre']=='good']['title'])[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = list(data[data['genre']=='economy']['body'])\n",
    "\n",
    "# news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for rev in news:\n",
    "#     if type(rev) == float:\n",
    "#         print(rev,i)\n",
    "#     i += 1\n",
    "# news[658]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>به گزارش گروه اقتصاد بین‌الملل فارس به نقل از ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>به گزارش گروه اقتصاد بین‌الملل فارس به نقل از ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>به گزارش خبرگزاری فارس به نقل از روابط عمومی و...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>به گزارش خبرگزاری فارس، شبکه تحلیلگران اقتصاد ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>به گزارش خبرنگار اقتصادی خبرگزاری فارس، بر اسا...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body\n",
       "0  به گزارش گروه اقتصاد بین‌الملل فارس به نقل از ...\n",
       "1  به گزارش گروه اقتصاد بین‌الملل فارس به نقل از ...\n",
       "2  به گزارش خبرگزاری فارس به نقل از روابط عمومی و...\n",
       "3  به گزارش خبرگزاری فارس، شبکه تحلیلگران اقتصاد ...\n",
       "4  به گزارش خبرنگار اقتصادی خبرگزاری فارس، بر اسا..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.DataFrame(news)\n",
    "news.rename(columns={0:'body'} , inplace=True)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary text exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch word count for each abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>به گزارش گروه اقتصاد بین‌الملل فارس به نقل از ...</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>به گزارش گروه اقتصاد بین‌الملل فارس به نقل از ...</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>به گزارش خبرگزاری فارس به نقل از روابط عمومی و...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>به گزارش خبرگزاری فارس، شبکه تحلیلگران اقتصاد ...</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>به گزارش خبرنگار اقتصادی خبرگزاری فارس، بر اسا...</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  word_count\n",
       "0  به گزارش گروه اقتصاد بین‌الملل فارس به نقل از ...         425\n",
       "1  به گزارش گروه اقتصاد بین‌الملل فارس به نقل از ...         364\n",
       "2  به گزارش خبرگزاری فارس به نقل از روابط عمومی و...         147\n",
       "3  به گزارش خبرگزاری فارس، شبکه تحلیلگران اقتصاد ...         724\n",
       "4  به گزارش خبرنگار اقتصادی خبرگزاری فارس، بر اسا...         601"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fetch wordcount for each abstract\n",
    "news['word_count'] = news['body'].apply(lambda x: len(str(x).split(\" \")))\n",
    "news[['body','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15694.000000\n",
       "mean       510.806168\n",
       "std        558.083765\n",
       "min         33.000000\n",
       "25%        214.250000\n",
       "50%        349.000000\n",
       "75%        619.000000\n",
       "max      27379.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Descriptive statistics of word counts\n",
    "news.word_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(news['body'].isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning data from none texts, digits, and ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_USELESS = r'[^\\w]'  # remove useless characters\n",
    "RE_DIGIT = r\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\"  # remove digits\n",
    "RE_SPACE = r'\\s+'  # remove space\n",
    "RE_EMAILS = r'[\\w\\.-]+@[\\w\\.-]+'\n",
    "RE_URLS = r'http\\S+'\n",
    "RE_WWW = r'www\\S+'\n",
    "\n",
    "\n",
    "def clean_all_save(document, save_file_path):\n",
    "    \"\"\"\n",
    "    this function generate raw persian text, it remove non-persian character\n",
    "    and all numbers and symbols\n",
    "    :param document:\n",
    "    :param save_file_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with open(save_file_path, 'w') as output:\n",
    "        for sentence in document:\n",
    "            sentence = clean_sentence(sentence)\n",
    "            output.write(sentence + '\\n')\n",
    "    return None\n",
    "\n",
    "\n",
    "# def clean_all(document, doc_pattern=r'<TEXT>(.*?)</TEXT>'):\n",
    "#     \"\"\"\n",
    "#     clean text like hamshahri, irBlogs, and other Treck format\n",
    "#     :param document:\n",
    "#     :param doc_pattern:\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "#     clean = ''\n",
    "#     document = re.findall(doc_pattern, document, re.DOTALL)\n",
    "#     for sentence in document:\n",
    "#         sentence = clean_sentence(sentence)\n",
    "#         clean += ' \\n' + sentence\n",
    "#     return clean\n",
    "\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    sentence = re.sub(r'[^\\u0621-\\u06ff]', ' ', sentence)\n",
    "    sentence = arToPersianChar(sentence)\n",
    "    sentence = arToPersianNumb(sentence)\n",
    "    sentence = faToEnglishNumb(sentence)\n",
    "    sentence = re.sub(r'[0-9]', ' ', sentence)\n",
    "    sentence = re.sub(RE_WWW, r' ', sentence)\n",
    "    sentence = re.sub(RE_URLS, r' ', sentence)\n",
    "    sentence = re.sub(RE_EMAILS, r' ', sentence)\n",
    "    sentence = re.sub(RE_USELESS, r' ', sentence)\n",
    "    sentence = re.sub(RE_DIGIT, r' ', sentence)\n",
    "    sentence = re.sub(RE_SPACE, r' ', sentence)\n",
    "    sentence = re.sub(r'[a-zA-Z]', ' ', sentence)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def arToPersianNumb(number):\n",
    "    dic = {\n",
    "        '١': '۱',\n",
    "        '٢': '۲',\n",
    "        '٣': '۳',\n",
    "        '٤': '۴',\n",
    "        '٥': '۵',\n",
    "        '٦': '۶',\n",
    "        '٧': '۷',\n",
    "        '٨': '۸',\n",
    "        '٩': '۹',\n",
    "        '٠': '۰',\n",
    "    }\n",
    "    return multiple_replace(dic, number)\n",
    "\n",
    "\n",
    "def arToPersianChar(userInput):\n",
    "    dic = {\n",
    "        'ك': 'ک',\n",
    "        'دِ': 'د',\n",
    "        'بِ': 'ب',\n",
    "        'زِ': 'ز',\n",
    "        'ذِ': 'ذ',\n",
    "        'شِ': 'ش',\n",
    "        'سِ': 'س',\n",
    "        'ى': 'ی',\n",
    "        'ي': 'ی'\n",
    "    }\n",
    "    return multiple_replace(dic, userInput)\n",
    "\n",
    "\n",
    "def faToEnglishNumb(number):\n",
    "    dic = {\n",
    "        '۰': '0',\n",
    "        '۱': '1',\n",
    "        '۲': '2',\n",
    "        '۳': '3',\n",
    "        '۴': '4',\n",
    "        '۵': '5',\n",
    "        '۶': '6',\n",
    "        '۷': '7',\n",
    "        '۸': '8',\n",
    "        '۹': '9',\n",
    "    }\n",
    "    return multiple_replace(dic, number)\n",
    "\n",
    "\n",
    "def multiple_replace(dic, text):\n",
    "    pattern = \"|\".join(map(re.escape, dic.keys()))\n",
    "    return re.sub(pattern, lambda m: dic[m.group()], str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all(document):\n",
    "    clean = ''\n",
    "    for sentence in document:\n",
    "        sentence = clean_sentence(sentence)\n",
    "        clean += sentence\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(pd.read_csv('STOPWORDS.csv',header=None)[0])\n",
    "# stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "j = k = i = 0\n",
    "news1 = []\n",
    "# labels1 = []\n",
    "# labels1 = list(labels.copy())\n",
    "normalizer = hazm.Normalizer()\n",
    "for review in news['body']:\n",
    "    sentences = normalizer.normalize(clean_all(review))\n",
    "    ##Convert to list from string\n",
    "    text = hazm.word_tokenize(sentences)\n",
    "    ##Stemming\n",
    "#     ps=PorterStemmer()\n",
    "    #Lemmatisation\n",
    "    lem = hazm.Lemmatizer()\n",
    "    text = [lem.lemmatize(word).split('#')[0] for word in text if not word in stopwords ] \n",
    "    text = \" \".join(text)\n",
    " \n",
    "    news1.append(text)\n",
    "    \n",
    "#     for j in range(len(sentences)):\n",
    "#         labels1.insert(i + k, labels[i])\n",
    "#         k += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'گزارش گروه اقتصاد الملل فارس نقل رویترز کشتی فله ایران محموله اوره برزیل قرار محموله ذرت ایران برگردند سوخت ماند زیرا شرکت دولت پتروبراس فروش سوخت بانکر علت تحریم آمریکا خوددار کرد آمار رهیاب کشتی داد کشتی مدل پاناماگذر کشتی عبور کانال پاناما دلربا گنج نزدیک بندر ایمبیتوبا جنوب برزیل لنگر انداخت قرار مسیر مشابه کشتی باوند ترمه مشکل سوخت کشتی مالکیت دولت ایران قرار تحریم قرار تامین اصل سوخت بانکر برزیل شرکت ترنس پترو شعبه پتروبراس شرکت فروش سوخت پتروبراس تنبیه آمریکا فعالیت هایش کشور مواجه کشتی کشتی پنجم دریابار موفق ترک برزیل محموله ذرت مسیر تجار دولت ایران دنبال بازار محصولات پتروشیمی جبران فروش نفت منبع صنعتی کشتیرانی دولت ایران ریسک کرد تمام کشتی دانست قادر سوخت مجدد بازگشت فرستاد علی رغم بیانیه پتروبراس کرد شرکت توانست کشتی سوخت فروخت منبع صنعتی انحصار سوختگیری مجدد بنادر برزیل اختیار شرکت دولت کشتی دریابار اوره برزیل آورد مشخص سوخت بازگشت تهیه کرد اساس آمار رهیاب کشتی کشتی نزدیک آفریقا جنوبی پتروبراس موضع تایید شرکت ریسک قرارداد بستن کشتی تحریم مسئولیت شرکت صادرکننده پتروبراس رویترز گزارش نوشت کشتی ایران هفته هاست بنادر برزیل لنگر انداخت علت نداشتن سوخت قادر  ایران بازگردند زیرا شرکت دولت نفت گاز پتروبراس برزیل فروش سوخت کشتی علت ترس تحریم آمریکا خوددار کرد اوپراتور بندر پاراناگوآ رویترز گفت کشتی باوند ترمه حامل اوره محصولات پتروشیمی کود شیمیایی ماه وارد برزیل انتظار رفت ذرت بارگیری ایران بازگردند سوخت کافی ادامه سفر جزئیات انتهای پیام'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving news to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data['body'][data['genre']=='economy'] = news1\n",
    "# data.to_excel(\"PreprocessedNews_economy.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4c868f2d7d89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meconomydata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genre'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'economy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0meconomydata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meconomydata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessed_via_HAZM_News_economy.xlsx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "economydata = data[data['genre']=='economy']\n",
    "economydata['body'] = news1\n",
    "economydata.to_excel(\"Preprocessed_via_HAZM_News_economy.xlsx\", index=False)\n",
    "# del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# economydata.to_excel(\"PreprocessedNews_economy.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15694\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>lead</th>\n",
       "      <th>body</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168316</td>\n",
       "      <td>2020-10-24 13:10:01</td>\n",
       "      <td>2020-10-24 13:10:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13980429000996</td>\n",
       "      <td>چهار کشتی ایرانی در انتظار سوخت در بنادر برزیل...</td>\n",
       "      <td>رویترز طی گزارشی نوشت دو کشتی دیگر ایران نیز د...</td>\n",
       "      <td>گزارش گروه اقتصاد الملل فارس نقل رویترز کشتی ف...</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168318</td>\n",
       "      <td>2020-10-24 13:10:03</td>\n",
       "      <td>2020-10-24 13:10:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13980429001007</td>\n",
       "      <td>نگرانی تجار برزیلی از خراب شدن تجارت با ایران/...</td>\n",
       "      <td>درحالی‌که رئیس‌جمهور برزیل تلاش می‌کند با جلب ...</td>\n",
       "      <td>گزارش گروه اقتصاد الملل فارس نقل رویترز ژائیر ...</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>168335</td>\n",
       "      <td>2020-10-24 13:10:13</td>\n",
       "      <td>2020-10-24 13:10:13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13980429001089</td>\n",
       "      <td>بیات عضو هیئت مدیره شرکت ملی صنایع پتروشیمی شد</td>\n",
       "      <td>وزیر نفت در حکمی، عبدالحسین بیات را به مدت سه ...</td>\n",
       "      <td>گزارش خبرگزاری فارس نقل روابط عموم وزارت نفت و...</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168366</td>\n",
       "      <td>2020-10-24 13:10:30</td>\n",
       "      <td>2020-10-24 13:10:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13980429001047</td>\n",
       "      <td>ضرورت راه اندازی پیام‌رسان مالی جایگزین سوئیفت...</td>\n",
       "      <td>در بخشی از گزارش شبکه تحلیلگران اقتصاد مقاومتی...</td>\n",
       "      <td>گزارش خبرگزاری فارس شبکه تحلیلگر اقتصاد مقاومت...</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170673</td>\n",
       "      <td>2020-10-24 13:29:26</td>\n",
       "      <td>2020-10-24 13:29:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13980431000516</td>\n",
       "      <td>افزایش 3386 واحدی شاخص بورس تهران</td>\n",
       "      <td>شاخص کل بورس اوراق بهادار تهران در پایان معامل...</td>\n",
       "      <td>گزارش خبرنگار اقتصاد خبرگزاری فارس اساس اطلاعا...</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id           created_at           updated_at  deleted_at  \\\n",
       "0  168316  2020-10-24 13:10:01  2020-10-24 13:10:01         NaN   \n",
       "1  168318  2020-10-24 13:10:03  2020-10-24 13:10:03         NaN   \n",
       "2  168335  2020-10-24 13:10:13  2020-10-24 13:10:13         NaN   \n",
       "3  168366  2020-10-24 13:10:30  2020-10-24 13:10:30         NaN   \n",
       "4  170673  2020-10-24 13:29:26  2020-10-24 13:29:26         NaN   \n",
       "\n",
       "             code                                              title  \\\n",
       "0  13980429000996  چهار کشتی ایرانی در انتظار سوخت در بنادر برزیل...   \n",
       "1  13980429001007  نگرانی تجار برزیلی از خراب شدن تجارت با ایران/...   \n",
       "2  13980429001089     بیات عضو هیئت مدیره شرکت ملی صنایع پتروشیمی شد   \n",
       "3  13980429001047  ضرورت راه اندازی پیام‌رسان مالی جایگزین سوئیفت...   \n",
       "4  13980431000516                  افزایش 3386 واحدی شاخص بورس تهران   \n",
       "\n",
       "                                                lead  \\\n",
       "0  رویترز طی گزارشی نوشت دو کشتی دیگر ایران نیز د...   \n",
       "1  درحالی‌که رئیس‌جمهور برزیل تلاش می‌کند با جلب ...   \n",
       "2  وزیر نفت در حکمی، عبدالحسین بیات را به مدت سه ...   \n",
       "3  در بخشی از گزارش شبکه تحلیلگران اقتصاد مقاومتی...   \n",
       "4  شاخص کل بورس اوراق بهادار تهران در پایان معامل...   \n",
       "\n",
       "                                                body    genre  \n",
       "0  گزارش گروه اقتصاد الملل فارس نقل رویترز کشتی ف...  economy  \n",
       "1  گزارش گروه اقتصاد الملل فارس نقل رویترز ژائیر ...  economy  \n",
       "2  گزارش خبرگزاری فارس نقل روابط عموم وزارت نفت و...  economy  \n",
       "3  گزارش خبرگزاری فارس شبکه تحلیلگر اقتصاد مقاومت...  economy  \n",
       "4  گزارش خبرنگار اقتصاد خبرگزاری فارس اساس اطلاعا...  economy  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "economydata = pd.read_excel(\"Preprocessed_via_HAZM_News_economy.xlsx\",engine='openpyxl')\n",
    "reviews1 = list(economydata['body'])\n",
    "\n",
    "print(len(reviews1))\n",
    "economydata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reviews1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common and uncommon words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify common words\n",
    "freq = pd.Series(' '.join(reviews1).split()).value_counts()\n",
    "f = list(pd.DataFrame(freq).index)\n",
    "# f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "خطرنشان             1\n",
       "مشیریه              1\n",
       "وپایش               1\n",
       "پژوهانه             1\n",
       "بازروی              1\n",
       "افتخارآفرینی‌های    1\n",
       "نیزپروندهای         1\n",
       "الشعیر              1\n",
       "پذر                 1\n",
       "کارشناسنان          1\n",
       "خبیثانه             1\n",
       "خاضر                1\n",
       "انعقادیک            1\n",
       "هردوباد             1\n",
       "سوارشویم            1\n",
       "سناریوسازی          1\n",
       "حوزه‌اند            1\n",
       "آموختگانی           1\n",
       "موستی               1\n",
       "نارضایی             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identify uncommon words\n",
    "freq1 =  pd.Series(' '.join(reviews1).split()).value_counts()[-20:]\n",
    "freq1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "781"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = pd.read_csv('STOPWORDS.csv',header=None)\n",
    "len(set(list(stop_words[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(stop_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1418"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word cloud for English and Persian\n",
    "\n",
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Minimal Example\n",
    "===============\n",
    "Generating a square wordcloud from the US constitution using default arguments.\n",
    "\"\"\"\n",
    "# Add another stopword\n",
    "\n",
    "# stopwords = add_stop_words(f[0:250])\n",
    "stopwords = add_stop_words(['میشه'])\n",
    "stopwords |= EN_STOPWORDS\n",
    "print(len(stopwords))\n",
    "stopwords |= set(list(stop_words[0]))\n",
    "stopwords |= set(['aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll',\n",
    "                  'mustn', 're',\n",
    "                  'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn',\n",
    "                  'اثر', 'البت', 'بالای', 'تول'\n",
    "                  , 'توی', 'تی', 'جلوی', 'حدود', 'خارج', 'دنبال', 'رسد', 'رود', 'سری','میشه', 'جواب بدین',\n",
    "                  'جواب بدید', 'میگه', 'اون','بدید', 'بدین', 'جواب','سلام',\n",
    "                  'سمت', 'ضد', 'طبق', 'عقب'\n",
    "                  , 'عل', 'قصد', 'مد', 'نزد', 'نزدیک', 'وسط', 'پاعین', 'ﺮﺗ', 'ﺱﺎﺳﺍﺮﺑ', 'ﺶﺷ', 'ﻪﺘﺷﺍﺪﻧ'])\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords = add_stop_words(['میشه'])\n",
    "# stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords1 = stopwords.copy()\n",
    "for st in stopwords1:\n",
    "    if type(st)==int or type(st)==float or type(st)==type(True):\n",
    "        stopwords.remove(st)\n",
    "        print(st)\n",
    "del stopwords1\n",
    "len(stopwords)\n",
    "stopwords = list(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Python program for insert and search \n",
    "# # operation in a Trie \n",
    "\n",
    "# class TrieNode: \n",
    "\n",
    "#     # Trie node class \n",
    "#     def __init__(self): \n",
    "#         self.children = [None]*80000\n",
    "\n",
    "#         # isEndOfWord is True if node represent the end of the word \n",
    "#         self.isEndOfWord = False\n",
    "\n",
    "# class Trie: \n",
    "\n",
    "#     # Trie data structure class \n",
    "#     def __init__(self): \n",
    "#         self.root = self.getNode() \n",
    "\n",
    "#     def getNode(self): \n",
    "\n",
    "#         # Returns new trie node (initialized to NULLs) \n",
    "#         return TrieNode() \n",
    "\n",
    "#     def _charToIndex(self,ch): \n",
    "\n",
    "#         # private helper function \n",
    "#         # Converts key current character into index \n",
    "#         # use only 'a' through 'z' and lower case \n",
    "\n",
    "#         return ord(ch)-ord('!') \n",
    "\n",
    "\n",
    "#     def insert(self,key): \n",
    "\n",
    "#         # If not present, inserts key into trie \n",
    "#         # If the key is prefix of trie node, \n",
    "#         # just marks leaf node \n",
    "#         pCrawl = self.root \n",
    "#         length = len(key) \n",
    "#         for level in range(length): \n",
    "#             index = self._charToIndex(key[level]) \n",
    "\n",
    "#             # if current character is not present \n",
    "#             if not pCrawl.children[index]: \n",
    "#                 pCrawl.children[index] = self.getNode() \n",
    "#             pCrawl = pCrawl.children[index] \n",
    "\n",
    "#         # mark last node as leaf \n",
    "#         pCrawl.isEndOfWord = True\n",
    "\n",
    "#     def search(self, key): \n",
    "\n",
    "#         # Search key in the trie \n",
    "#         # Returns true if key presents \n",
    "#         # in trie, else false \n",
    "#         pCrawl = self.root \n",
    "#         length = len(key) \n",
    "#         for level in range(length): \n",
    "#             index = self._charToIndex(key[level]) \n",
    "#             if not pCrawl.children[index]: \n",
    "#                 return False\n",
    "#             pCrawl = pCrawl.children[index] \n",
    "\n",
    "#         return pCrawl != None and pCrawl.isEndOfWord \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# keys = list(stopwords)\n",
    "\n",
    "# # Trie object \n",
    "# t = Trie() \n",
    "\n",
    "# # Construct trie \n",
    "# for key in keys: \n",
    "#     t.insert(key) \n",
    "\n",
    "# # reviews = reviews1.copy()\n",
    "# # for rev in reviews1:\n",
    "# # #     rev = rev.replace('\\u200c',' ')\n",
    "# # #         rev = rev.replace('\\u200f',' ')\n",
    "# # #         rev = re.sub(r'[^a-zA-Z0-9آ-ی۰-۹ ]', ' ', rev)\n",
    "# #     words = rev.split(' ')\n",
    "\n",
    "# #     words1 = words.copy()\n",
    "# #     for w in words:\n",
    "# #         if w == '':\n",
    "# #             words1.remove(w)\n",
    "# #             continue\n",
    "# #         if t.search(w):\n",
    "# #             words1.remove(w)\n",
    "\n",
    "# #     words = words1\n",
    "# #     text = ''\n",
    "# #     for w in words:\n",
    "# #         text += w + ' '\n",
    "# #     reviews[i] = text\n",
    "# #     i += 1\n",
    "\n",
    "# # reviews1 = reviews.copy()\n",
    "# # del reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ord('!')-ord('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input keys (use only 'a' through 'z' and lower case) \n",
    "# keys = list(stopwords.loc[:,0])\n",
    "\n",
    "# output = [\"Not present in trie\", \n",
    "#         \"Present in trie\"] \n",
    "\n",
    "# # Trie object \n",
    "# t = Trie() \n",
    "\n",
    "# # Construct trie \n",
    "# for key in keys: \n",
    "#     t.insert(key) \n",
    "\n",
    "\n",
    "# print(\"{} ---- {}\".format(\"از\",output[t.search(\"از\")])) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### stopword deletion Testing\n",
    "# rev = reviews1[0]\n",
    "\n",
    "# print(rev)\n",
    "# #rev = rev.replace('\\u200c',' ')\n",
    "# rev = rev.replace('\\u200f',' ')\n",
    "# rev = re.sub(r'[^a-zA-Z0-9آ-ی۰-۹ ]', ' ', rev)\n",
    "# rev.split(' ')\n",
    "# words = rev.split()\n",
    "\n",
    "# words1 = words.copy()\n",
    "# for w in words:\n",
    "#     if w == '':\n",
    "#         words1.remove(w)\n",
    "#         continue\n",
    "#     if t.search(w):\n",
    "#         words1.remove(w)\n",
    "\n",
    "# words = words1\n",
    "# text = ''\n",
    "# for w in words:\n",
    "#     text += w + ' '\n",
    "# text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for rev in reviews1:\n",
    "#     if type(rev) == float:\n",
    "#         print(rev,i)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop word deleting finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you wish to withdraw stopword deletion, uncomment the below line, and run it.\n",
    "# reviews = reviews1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #cleaning dataset\n",
    "# #word_tokenize\n",
    "# words=[]\n",
    "# all_text = ''\n",
    "# # stemmer = Stemmer()\n",
    "# for i in range (len(reviews)):\n",
    "#     text = reviews[i]\n",
    "# #     text = text.replace('\\u200c',' ')\n",
    "#     text = text.replace('\\u200f',' ')\n",
    "#     text = re.sub(r'[^a-zA-Z0-9آ-ی۰-۹ ]', ' ', text)\n",
    "#     all_text += text\n",
    "#     all_text += ' '\n",
    "#     wordsInText = text.split()\n",
    "#     for word in wordsInText:\n",
    "#         if word != ' ' or word != '':\n",
    "#             words.append(word)\n",
    "# len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "nulltextindex = []\n",
    "holdingCorpus = reviews1.copy()\n",
    "corpus1 = reviews1.copy()\n",
    "for rev in corpus1:\n",
    "#     rev = rev.replace('\\u200c',' ')\n",
    "    rev = rev.replace('\\u200f',' ')\n",
    "    rev = re.sub(r'[^a-zA-Zآ-ی]', ' ', rev)\n",
    "    rev.split(' ')\n",
    "    words = rev.split(' ')\n",
    "\n",
    "    words1 = words.copy()\n",
    "    for w in words:\n",
    "        if w == ''or type(w)==int or type(w)==float or type(w)==bool:\n",
    "            words1.remove(w)\n",
    "            continue\n",
    "        if w in stopwords:\n",
    "            words1.remove(w)\n",
    "\n",
    "    words = words1.copy()\n",
    "    text = ''\n",
    "    for w in words:\n",
    "        text += w + ' '\n",
    "    corpus1[i] = text\n",
    "    if type(text)!= str or len(text)==0 :\n",
    "        nulltextindex.append(i)\n",
    "    i += 1\n",
    "corpus = corpus1.copy()\n",
    "del corpus1\n",
    "nulltextindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for tex in corpus:\n",
    "    text = text+ '\\n' +tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wodcloud = WordCloudFa(no_reshape=False, persian_normalize=True, include_numbers=False,\n",
    "                       collocations=False, width=1200, height=900)\n",
    "\n",
    "wc = wodcloud.generate(text)\n",
    "image = wc.to_image()\n",
    "image.show()\n",
    "image.save('wordcloud.png')\n",
    "\n",
    "print(wc)\n",
    "fig = plt.figure(1)\n",
    "\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVec = CountVectorizer(max_df=0.8, stop_words=stopwords, max_features=100000, ngram_range=(1, 3))\n",
    "X = CountVec.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(CountVec.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Most frequently occuring words\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in      \n",
    "                   vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], \n",
    "                       reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "\n",
    "#Convert most freq words to dataframe for plotting bar plot\n",
    "top_words = get_top_n_words(corpus, n=20)\n",
    "top_df = pd.DataFrame(top_words)\n",
    "top_df.columns=[\"Word\", \"Freq\"]\n",
    "print(top_df)\n",
    "#Barplot of most freq words\n",
    "sns.set(rc={'figure.figsize':(13, 8)})\n",
    "g = sns.barplot(x=\"Word\", y=\"Freq\", data=top_df)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most frequently occuring Bi-grams\n",
    "def get_top_n2_words(corpus, n=None):\n",
    "    vec1 = CountVectorizer(ngram_range=(2,2),  \n",
    "            max_features=2000).fit(corpus)\n",
    "    bag_of_words = vec1.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     \n",
    "                  vec1.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], \n",
    "                reverse=True)\n",
    "    return words_freq[:n]\n",
    "top2_words = get_top_n2_words(corpus, n=20)\n",
    "top2_df = pd.DataFrame(top2_words)\n",
    "top2_df.columns=[\"Bi-gram\", \"Freq\"]\n",
    "print(top2_df)\n",
    "#Barplot of most freq Bi-grams\n",
    "\n",
    "sns.set(rc={'figure.figsize':(13,8)})\n",
    "h=sns.barplot(x=\"Bi-gram\", y=\"Freq\", data=top2_df)\n",
    "h.set_xticklabels(h.get_xticklabels(), rotation=45, name = 'XB Niloofar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
